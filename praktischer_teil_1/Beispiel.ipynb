{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Zuerst definieren wir Header, um unseren Bot zu kennzeichnen und rufen die Seite mit requests ab.",
   "id": "cd635fbf80f4a1a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "url = 'https://de.wikipedia.org/wiki/Liste_der_Mitglieder_des_1._Ernannten_Landtages_Nordrhein-Westfalen'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'My User Agent',\n",
    "    'From': 'kalange@statistik.tu-dortmund.de'\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response)"
   ],
   "id": "522b21c9bb93669c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wir können Beautifulsoup benutzen, um die HTML zu parsen. Mit dem \"find\" Befehl können wir gezielt nach HTML-Elementen suchen. Hier suchen wir nach einem Element mit der ID \"firstHeading\", also der ersten Überschrift, und geben ihren Text aus.",
   "id": "e157f92ae43f821f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "title = soup.find('h1', id='firstHeading').get_text()\n",
    "print(\"Titel:\", title)"
   ],
   "id": "4199f1eb7db94abc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Genau so können wir auch nach unserer Tabelle suchen. Sie hat die Klasse \"wikitable\". Sobald wir sie gefunden haben, müssen wir noch den Körper der Tabelle aufrufen (\"tbody\") und können dann alle Zeilen (\"tr\") auslesen.",
   "id": "739d4fa19576c664"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "abgeordnete = soup.find('table', class_='wikitable')\n",
    "abgeordnete = abgeordnete.find(\"tbody\")\n",
    "rows = abgeordnete.find_all('tr')"
   ],
   "id": "86924c5d981e8c3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Da die Tabelle etwas sperrig aufgebaut ist, müssen wir sie etwas aufbereiten. Zuerst extrahieren wir die Spaltenüberschriften aus der ersten Zeile. Dann iterieren wir über die restlichen Zeilen und fügen sie in ein Pandas DataFrame ein. Am Ende speichern wir das DataFrame als CSV-Datei.",
   "id": "91eb6f87c3b5d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "columns = rows[0].get_text().removeprefix(\"\\n\").removesuffix(\"\\n\").split(\"\\n\\n\")\n",
    "rows = rows[1:]\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "for row in rows:\n",
    "    data = pd.concat([data,\n",
    "                      pd.DataFrame([row.get_text().removeprefix(\"\\n\").removesuffix(\"\\n\").split(\"\\n\\n\")],\n",
    "                                   columns=columns)], ignore_index=True)\n",
    "\n",
    "data.to_csv(\"abgeordneten.csv\")"
   ],
   "id": "c0016e5c38491c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
